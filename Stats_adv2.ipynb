{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question1. Explain the properties of the F-distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Answer1.\n",
    "The F-distribution is a continuous probability distribution that arises frequently in statistical hypothesis testing, particularly in ANOVA (Analysis of Variance). It's characterized by the following properties:   \n",
    "\n",
    "Positive Values: The F-distribution is defined only for positive values.   \n",
    "Asymmetric: Unlike the normal distribution, the F-distribution is skewed to the right.   \n",
    "Shape: The shape of the F-distribution depends on two parameters: the degrees of freedom for the numerator (df1) and the degrees of freedom for the denominator (df2). As these degrees of freedom increase, the F-distribution approaches a normal distribution.   \n",
    "Mean and Variance:\n",
    "Mean: The mean of the F-distribution is df2 / (df2 - 2), for df2 > 2.\n",
    "Variance: The variance is more complex and depends on both df1 and df2.\n",
    "Use in Hypothesis Testing:\n",
    "The F-distribution is used to test the equality of variances of two populations or to compare the means of multiple groups in ANOVA.   \n",
    "The F-statistic, calculated as the ratio of two variances, follows an F-distribution under the null hypothesis\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Answer2.\n",
    "The F-distribution is primarily used in two types of statistical tests:\n",
    "\n",
    "1. Testing for Equality of Variances:\n",
    "\n",
    "One-way ANOVA: This test compares the means of multiple groups. To perform this test, we assume that the populations have equal variances. The F-test is used to check this assumption. If the F-test is significant, it indicates that the variances are not equal, and the results of the ANOVA may be unreliable.\n",
    "Two-sample t-test: While the t-test is used to compare the means of two groups, it assumes equal variances. The F-test can be used to verify this assumption before conducting the t-test.\n",
    "2. Analysis of Variance (ANOVA):\n",
    "\n",
    "One-way ANOVA: As mentioned earlier, ANOVA compares the means of multiple groups. The F-test is used to determine whether there are significant differences among the group means.\n",
    "Two-way ANOVA: This test examines the effects of two categorical independent variables on a continuous dependent variable. The F-test is used to assess the main effects of each factor and their interaction effect.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question3.  What are the key assumptions required for conducting an F-test to compare the variances of two populations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Answer3.\n",
    "To conduct an F-test to compare the variances of two populations, the following key assumptions must be met:\n",
    "\n",
    "Independence: The two samples must be independent of each other. This means that the selection of one sample should not influence the selection of the other.\n",
    "Normality: Both populations from which the samples are drawn should be normally distributed. While this assumption is crucial, especially for small sample sizes, it can be relaxed to some extent for larger sample sizes due to the Central Limit Theorem.\n",
    "Homogeneity of Variance (Equal Variances): This assumption, although counterintuitive as we're testing for equal variances, is often implicitly assumed. However, there are alternative tests like Levene's test or Bartlett's test to assess the equality of variances before conducting the F-test.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question4. What is the purpose of ANOVA, and how does it differ from a t-test? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Answer4.\n",
    "Purpose of ANOVA vs. t-test\n",
    "ANOVA (Analysis of Variance) and t-tests are both statistical tests used to compare means of different groups. However, they differ in the number of groups they can compare: \n",
    "\n",
    "ANOVA\n",
    "Purpose: To compare the means of three or more groups to determine if there are significant differences among them. \n",
    "How it works: ANOVA analyzes the variance within each group and the variance between groups. If the variance between groups is significantly larger than the variance within groups, it suggests that there are significant differences between the means of the groups. \n",
    "t-test\n",
    "Purpose: To compare the means of two groups to determine if there is a significant difference between them. \n",
    "How it works: A t-test calculates a t-statistic, which measures the difference between the two group means relative to the variability within the groups.\n",
    "\n",
    "While ANOVA can tell you if there is an overall difference among the groups, it doesn't tell you which specific groups differ from each other. For this, post-hoc tests like Tukey's HSD or Bonferroni correction are used. \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Answer5.\n",
    "When to Use One-Way ANOVA Instead of Multiple t-tests\n",
    "One-way ANOVA is preferred over multiple t-tests when comparing the means of more than two groups for the following reasons:\n",
    "\n",
    "Controlling Type I Error Rate:\n",
    "\n",
    "Multiple Comparisons Problem: When conducting multiple t-tests, the overall Type I error rate (the probability of incorrectly rejecting a true null hypothesis) increases. This is because each test has a certain probability of making a Type I error. \n",
    "ANOVA's Advantage: ANOVA addresses this issue by performing a single overall test. This helps control the Type I error rate, making it more reliable. \n",
    "Efficiency:\n",
    "\n",
    "Reduced Computational Burden: ANOVA is a more efficient statistical method than conducting multiple pairwise t-tests. It requires fewer calculations and less time to analyze the data.\n",
    "Comprehensive Analysis:\n",
    "\n",
    "Overall Group Differences: ANOVA can assess whether there are significant differences among the means of all groups simultaneously. \n",
    "Post-hoc Tests: If the overall ANOVA is significant, post-hoc tests like Tukey's HSD or Bonferroni correction can be used to identify specific pairwise differences between groups, while still controlling the Type I error rate. \n",
    "In summary:\n",
    "\n",
    "One-way ANOVA is a more powerful and statistically sound approach when comparing the means of multiple groups.\n",
    "It helps to maintain the overall Type I error rate and provides a more comprehensive analysis of group differences. \n",
    "Multiple t-tests, while simpler to understand, can lead to inflated Type I error rates, especially when many comparisons are made. \n",
    "By using one-way ANOVA, researchers can draw more reliable conclusions about the differences between groups and avoid the pitfalls associated with multiple pairwise comparisons\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question6. Explain how variance is partitioned in ANOVA into between-group variance and within-group variance. How does this partitioning contribute to the calculation of the F-statistic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Answer6.\n",
    "Partitioning Variance in ANOVA\n",
    "In ANOVA, the total variance in a dataset is partitioned into two components: \n",
    "\n",
    "Between-Group Variance: This measures the variability between the means of different groups. It reflects the differences in the average values of the dependent variable across the groups.\n",
    "Within-Group Variance: This measures the variability within each group. It reflects the natural variation among individuals within the same group.\n",
    "Calculating the F-statistic:\n",
    "\n",
    "The F-statistic is calculated by comparing the between-group variance to the within-group variance. It's essentially a ratio of these two variances: \n",
    "\n",
    "F = (Between-group variance) / (Within-group variance)\n",
    "A higher F-statistic indicates that the differences between group means are larger relative to the variability within groups. This suggests that the independent variable has a significant effect on the dependent variable. \n",
    "\n",
    "Key Points:\n",
    "\n",
    "Null Hypothesis: The null hypothesis in ANOVA is that all group means are equal. \n",
    "Alternative Hypothesis: The alternative hypothesis is that at least one group mean is different from the others. \n",
    "F-distribution: The F-statistic follows an F-distribution with specific degrees of freedom. \n",
    "P-value: The p-value associated with the F-statistic helps determine the statistical significance of the results.\n",
    "By partitioning the variance and calculating the F-statistic, ANOVA allows us to assess whether the observed differences between group means are likely due to chance or a real effect of the independent variable.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question7.Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Answer 7.\n",
    "Classical (Frequentist) vs. Bayesian ANOVA\n",
    "Uncertainty\n",
    "Classical: Uncertainty is expressed in terms of p-values and confidence intervals. These are calculated based on the assumption of repeated sampling from the same population. \n",
    "Bayesian: Uncertainty is expressed in terms of probability distributions. Bayesian methods assign probabilities to hypotheses and parameters, allowing for more nuanced interpretations of uncertainty. \n",
    "Parameter Estimation\n",
    "Classical: Parameter estimates are point estimates (e.g., sample mean) and are considered fixed, true values. Confidence intervals are used to quantify uncertainty around these point estimates. \n",
    "Bayesian: Parameters are treated as random variables with probability distributions. Bayesian methods use prior beliefs about the parameters, combined with observed data, to obtain posterior distributions. These posterior distributions represent the updated beliefs about the parameters, incorporating both prior knowledge and observed data. \n",
    "Hypothesis Testing\n",
    "Classical: Hypothesis testing involves setting up null and alternative hypotheses and calculating a test statistic (e.g., F-statistic). The p-value is used to determine whether to reject or fail to reject the null hypothesis. \n",
    "Bayesian: Hypothesis testing in Bayesian statistics involves calculating the posterior probability of each hypothesis given the observed data. This allows for a more nuanced interpretation of evidence, as it quantifies the relative support for different hypotheses.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question8.Question: You have two sets of data representing the incomes of two different professions1\n",
    "# V Profession A: [48, 52, 55, 60, 62'\n",
    "# V Profession B: [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions'\n",
    "# incomes are equal. What are your conclusions based on the F-test?\n",
    "\n",
    "# Task: Use Python to calculate the F-statistic and p-value for the given data.\n",
    "\n",
    "# Objective: Gain experience in performing F-tests and interpreting the results in terms of variance comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 3.232989690721649\n",
      "p-value: 0.10987970118946545\n"
     ]
    }
   ],
   "source": [
    "'''Answer 8'''\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Data for Profession A and B\n",
    "profession_A = [48, 52, 55, 60, 62]\n",
    "profession_B = [45, 50, 55, 52, 47]\n",
    "\n",
    "# Calculate the F-statistic and p-value\n",
    "F_statistic, p_value = stats.f_oneway(profession_A, profession_B)\n",
    "\n",
    "print(\"F-statistic:\", F_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "'''Interpreting the Results:\n",
    "\n",
    "F-statistic: This measures the ratio of the variances of the two groups. A larger F-statistic suggests that the variances are significantly different.\n",
    "p-value: This is the probability of observing an F-statistic as extreme as the one calculated, assuming the null hypothesis is true. A smaller p-value indicates stronger evidence against the null hypothesis. \n",
    "Decision Rule:\n",
    "\n",
    "Significance Level: Choose a significance level (e.g., 0 = 0.05).\n",
    "Comparison: If the p-value is less than the significance level, reject the null hypothesis. Otherwise, fail to reject the null hypothesis. \n",
    "Conclusion:\n",
    "\n",
    "Based on the calculated F-statistic and p-value, we can make a conclusion about the equality of variances between the two professions' incomes.\n",
    "\n",
    "If the p-value is less than the significance level, we can conclude that the variances are significantly different. If the p-value is greater than the significance level, we cannot reject the null hypothesis, and we cannot conclude that the variances are significantly different. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Question9.Question: Conduct a one-way ANOVA to test whether there are any statistically significant differences in\n",
    "# average heights between three different regions with the following data1\n",
    "# V Region A: [160, 162, 165, 158, 164'\n",
    "# V Region B: [172, 175, 170, 168, 174'\n",
    "# V Region C: [180, 182, 179, 185, 183'\n",
    "# V Task: Write Python code to perform the one-way ANOVA and interpret the results.\n",
    "# V Objective: Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 67.87330316742101\n",
      "p-value: 2.8706641879370266e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Interpreting the Results:\\n\\nF-statistic: This measures the ratio of the variance between groups to the variance within groups. A larger F-statistic suggests that the differences between group means are significant.\\np-value: This is the probability of observing an F-statistic as extreme as the one calculated, assuming the null hypothesis is true. A smaller p-value indicates stronger evidence against the null hypothesis. \\nDecision Rule:\\n\\nSignificance Level: Choose a significance level (e.g., α = 0.05).\\nComparison: If the p-value is less than the significance level, reject the null hypothesis. Otherwise, fail to reject the null hypothesis. \\nConclusion:\\n\\nBased on the calculated F-statistic and p-value, we can make a conclusion about the equality of means between the three regions.\\n\\nIf the p-value is less than the significance level, we can conclude that there are significant differences in the average heights between at least two of the regions. If the p-value is greater than the significance level, we cannot reject the null hypothesis, and we cannot conclude that there are significant differences between the regions.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Answer9.\n",
    "'''\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Data for the three regions\n",
    "region_A = [160, 162, 165, 158, 164]\n",
    "region_B = [172, 175, 170, 168, 174]\n",
    "region_C = [180, 182, 179, 185, 183]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(region_A, region_B, region_C)\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "'''Interpreting the Results:\n",
    "\n",
    "F-statistic: This measures the ratio of the variance between groups to the variance within groups. A larger F-statistic suggests that the differences between group means are significant.\n",
    "p-value: This is the probability of observing an F-statistic as extreme as the one calculated, assuming the null hypothesis is true. A smaller p-value indicates stronger evidence against the null hypothesis. \n",
    "Decision Rule:\n",
    "\n",
    "Significance Level: Choose a significance level (e.g., 0 = 0.05).\n",
    "Comparison: If the p-value is less than the significance level, reject the null hypothesis. Otherwise, fail to reject the null hypothesis. \n",
    "Conclusion:\n",
    "\n",
    "Based on the calculated F-statistic and p-value, we can make a conclusion about the equality of means between the three regions.\n",
    "\n",
    "If the p-value is less than the significance level, we can conclude that there are significant differences in the average heights between at least two of the regions. If the p-value is greater than the significance level, we cannot reject the null hypothesis, and we cannot conclude that there are significant differences between the regions.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
